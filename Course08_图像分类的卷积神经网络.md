介绍如下卷积神经网络：**不做详细介绍**

- LeNet：Yan LeCun等人于1998年第一次将卷积神经网络应用到图像分类任务上[1]，在手写数字识别任务上取得了巨大成功。

- AlexNet：Alex Krizhevsky等人在2012年提出了AlexNet[2], 并应用在大尺寸图片数据集ImageNet上，获得了2012年ImageNet比赛冠军(ImageNet Large Scale Visual Recognition Challenge，ILSVRC）。

- VGG：Simonyan和Zisserman于2014年提出了VGG网络结构[3]，是当前最流行的卷积神经网络之一，由于其结构简单、应用性极强而深受广大研究者欢迎。

- GoogLeNet：Christian Szegedy等人在2014提出了GoogLeNet[4]，并取得了2014年ImageNet比赛冠军。

- ResNet：Kaiming He等人在2015年提出了ResNet[5]，通过引入残差模块加深网络层数，在ImagNet数据集上的错误率降低到3.6%，超越了人眼识别水平。ResNet的设计思想深刻地影响了后来的深度神经网络的设计。

# LeNet

LeNet是最早的卷积神经网络之一。

- 第一模块：**包含5×5的6通道卷积和2×2的池化**。卷积提取图像中包含的特征模式（激活函数使用sigmoid），图像尺寸从32减小到28。经过池化层可以降低输出特征图对空间位置的敏感性，图像尺寸减到14。

- 第二模块：**和第一模块尺寸相同，通道数由6增加为16**。卷积操作使图像尺寸减小到10，经过池化后变成5。

- 第三模块：**包含5×5的120通道卷积。**卷积之后的图像尺寸减小到1，但是通道数增加为120。将经过第3次卷积提取到的特征图输入到全连接层。第一个全连接层的输出神经元的个数是64，第二个全连接层的输出神经元个数是分类标签的类别数，对于手写数字识别其大小是10。然后使用Softmax激活函数即可计算出每个类别的预测概率。


# AlexNet

通过上面的实际训练可以看到，虽然LeNet在手写数字识别数据集上取得了很好的结果，但在更大的数据集上表现却并不好。AlexNet与LeNet相比，具有更深的网络结构，包含5层卷积和3层全连接，同时使用了如下三种方法改进模型的训练过程：

- 数据增广：深度学习中常用的一种处理方式，通过对训练随机加一些变化，比如平移、缩放、裁剪、旋转、翻转或者增减亮度等，产生一系列跟原始图片相似但又不完全相同的样本，从而扩大训练数据集。通过这种方式，可以随机改变训练样本，避免模型过度依赖于某些属性，能从一定程度上抑制过拟合。

- 使用Dropout抑制过拟合

- 使用ReLU激活函数减少梯度消失现象

# VGG

VGG是当前最流行的CNN模型之一，2014年由Simonyan和Zisserman提出，其命名来源于论文作者所在的实验室Visual Geometry Group。VGG通过使用一系列大小为3x3的小尺寸卷积核和pooling层构造深度卷积神经网络，并取得了较好的效果。VGG模型因为结构简单、应用性极强而广受研究者欢迎，尤其是它的网络结构设计方法，为构建深度神经网络提供了方向。

# GoogLeNet

于图像信息在空间尺寸上的巨大差异，如何选择合适的卷积核大小来提取特征就显得比较困难了。空间分布范围更广的图像信息适合用较大的卷积核来提取其特征，而空间分布范围较小的图像信息则适合用较小的卷积核来提取其特征。为了解决这个问题，GoogLeNet提出了一种被称为Inception模块的方案。


**说明：**

- Google的研究人员为了向LeNet致敬，特地将模型命名为GoogLeNet
- Inception一词来源于电影《盗梦空间》（Inception）


# ResNet

Kaiming He等人提出了残差网络ResNet来解决上述问题，其基本思想如 图6所示。

- 图6(a)：表示增加网络的时候，将x映射成y=F(x)y=F(x)y=F(x)输出。
- 图6(b)：对图6(a)作了改进，输出y=F(x)+xy=F(x) + xy=F(x)+x。这时不是直接学习输出特征y的表示，而是学习y−xy-xy−x。
  - 如果想学习出原模型的表示，只需将F(x)的参数全部设置为0，则y=xy=xy=x是恒等映射。
  - F(x)=y−xF(x) = y - xF(x)=y−x也叫做残差项，如果x→yx\rightarrow yx→y的映射接近恒等映射，图6(b)中通过学习残差项也比图6(a)学习完整映射形式更加容易。





